{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":99552,"databundleVersionId":13190393,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-30T06:10:50.175259Z","iopub.execute_input":"2025-07-30T06:10:50.175445Z","iopub.status.idle":"2025-07-30T06:10:52.732397Z","shell.execute_reply.started":"2025-07-30T06:10:50.175422Z","shell.execute_reply":"2025-07-30T06:10:52.731688Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"train_csv = pd.read_csv('/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv')\nprint(train_csv.info())\nprint(\"\\n\" + \"-\"*50 + \"\\n\")\ntrain_csv.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T06:10:52.733055Z","iopub.execute_input":"2025-07-30T06:10:52.733286Z","iopub.status.idle":"2025-07-30T06:10:52.830224Z","shell.execute_reply.started":"2025-07-30T06:10:52.733270Z","shell.execute_reply":"2025-07-30T06:10:52.829596Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4405 entries, 0 to 4404\nData columns (total 18 columns):\n #   Column                                      Non-Null Count  Dtype \n---  ------                                      --------------  ----- \n 0   SeriesInstanceUID                           4405 non-null   object\n 1   PatientAge                                  4405 non-null   int64 \n 2   PatientSex                                  4405 non-null   object\n 3   Modality                                    4405 non-null   object\n 4   Left Infraclinoid Internal Carotid Artery   4405 non-null   int64 \n 5   Right Infraclinoid Internal Carotid Artery  4405 non-null   int64 \n 6   Left Supraclinoid Internal Carotid Artery   4405 non-null   int64 \n 7   Right Supraclinoid Internal Carotid Artery  4405 non-null   int64 \n 8   Left Middle Cerebral Artery                 4405 non-null   int64 \n 9   Right Middle Cerebral Artery                4405 non-null   int64 \n 10  Anterior Communicating Artery               4405 non-null   int64 \n 11  Left Anterior Cerebral Artery               4405 non-null   int64 \n 12  Right Anterior Cerebral Artery              4405 non-null   int64 \n 13  Left Posterior Communicating Artery         4405 non-null   int64 \n 14  Right Posterior Communicating Artery        4405 non-null   int64 \n 15  Basilar Tip                                 4405 non-null   int64 \n 16  Other Posterior Circulation                 4405 non-null   int64 \n 17  Aneurysm Present                            4405 non-null   int64 \ndtypes: int64(15), object(3)\nmemory usage: 619.6+ KB\nNone\n\n--------------------------------------------------\n\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                   SeriesInstanceUID  PatientAge PatientSex  \\\n0  1.2.826.0.1.3680043.8.498.10004044428023505108...          64     Female   \n1  1.2.826.0.1.3680043.8.498.10004684224894397679...          76     Female   \n2  1.2.826.0.1.3680043.8.498.10005158603912009425...          58       Male   \n\n  Modality  Left Infraclinoid Internal Carotid Artery  \\\n0      MRA                                          0   \n1      MRA                                          0   \n2      CTA                                          0   \n\n   Right Infraclinoid Internal Carotid Artery  \\\n0                                           0   \n1                                           0   \n2                                           0   \n\n   Left Supraclinoid Internal Carotid Artery  \\\n0                                          0   \n1                                          0   \n2                                          0   \n\n   Right Supraclinoid Internal Carotid Artery  Left Middle Cerebral Artery  \\\n0                                           0                            0   \n1                                           0                            0   \n2                                           0                            0   \n\n   Right Middle Cerebral Artery  Anterior Communicating Artery  \\\n0                             0                              0   \n1                             0                              0   \n2                             0                              0   \n\n   Left Anterior Cerebral Artery  Right Anterior Cerebral Artery  \\\n0                              0                               0   \n1                              0                               0   \n2                              0                               0   \n\n   Left Posterior Communicating Artery  Right Posterior Communicating Artery  \\\n0                                    0                                     0   \n1                                    0                                     0   \n2                                    0                                     0   \n\n   Basilar Tip  Other Posterior Circulation  Aneurysm Present  \n0            0                            0                 0  \n1            0                            0                 0  \n2            0                            1                 1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SeriesInstanceUID</th>\n      <th>PatientAge</th>\n      <th>PatientSex</th>\n      <th>Modality</th>\n      <th>Left Infraclinoid Internal Carotid Artery</th>\n      <th>Right Infraclinoid Internal Carotid Artery</th>\n      <th>Left Supraclinoid Internal Carotid Artery</th>\n      <th>Right Supraclinoid Internal Carotid Artery</th>\n      <th>Left Middle Cerebral Artery</th>\n      <th>Right Middle Cerebral Artery</th>\n      <th>Anterior Communicating Artery</th>\n      <th>Left Anterior Cerebral Artery</th>\n      <th>Right Anterior Cerebral Artery</th>\n      <th>Left Posterior Communicating Artery</th>\n      <th>Right Posterior Communicating Artery</th>\n      <th>Basilar Tip</th>\n      <th>Other Posterior Circulation</th>\n      <th>Aneurysm Present</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.2.826.0.1.3680043.8.498.10004044428023505108...</td>\n      <td>64</td>\n      <td>Female</td>\n      <td>MRA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.2.826.0.1.3680043.8.498.10004684224894397679...</td>\n      <td>76</td>\n      <td>Female</td>\n      <td>MRA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.2.826.0.1.3680043.8.498.10005158603912009425...</td>\n      <td>58</td>\n      <td>Male</td>\n      <td>CTA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"train_csv['Modality'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T06:10:52.831689Z","iopub.execute_input":"2025-07-30T06:10:52.832289Z","iopub.status.idle":"2025-07-30T06:10:52.837856Z","shell.execute_reply.started":"2025-07-30T06:10:52.832270Z","shell.execute_reply":"2025-07-30T06:10:52.837323Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Modality\nCTA           1857\nMRA           1256\nMRI T2         986\nMRI T1post     306\nName: count, dtype: int64"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"train_localizers_csv = pd.read_csv('/kaggle/input/rsna-intracranial-aneurysm-detection/train_localizers.csv')\nprint(train_localizers_csv.info())\nprint(\"\\n\" + \"-\"*50 + \"\\n\")\ntrain_localizers_csv.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T06:10:52.838478Z","iopub.execute_input":"2025-07-30T06:10:52.838701Z","iopub.status.idle":"2025-07-30T06:10:52.883357Z","shell.execute_reply.started":"2025-07-30T06:10:52.838679Z","shell.execute_reply":"2025-07-30T06:10:52.882633Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2286 entries, 0 to 2285\nData columns (total 4 columns):\n #   Column             Non-Null Count  Dtype \n---  ------             --------------  ----- \n 0   SeriesInstanceUID  2286 non-null   object\n 1   SOPInstanceUID     2286 non-null   object\n 2   coordinates        2286 non-null   object\n 3   location           2286 non-null   object\ndtypes: object(4)\nmemory usage: 71.6+ KB\nNone\n\n--------------------------------------------------\n\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                   SeriesInstanceUID  \\\n0  1.2.826.0.1.3680043.8.498.10005158603912009425...   \n1  1.2.826.0.1.3680043.8.498.10022796280698534221...   \n2  1.2.826.0.1.3680043.8.498.10023411164590664678...   \n\n                                      SOPInstanceUID  \\\n0  1.2.826.0.1.3680043.8.498.10775329348174902199...   \n1  1.2.826.0.1.3680043.8.498.53868409774237283281...   \n2  1.2.826.0.1.3680043.8.498.24186535344744886473...   \n\n                                         coordinates  \\\n0    {'x': 258.3621186176837, 'y': 261.359900373599}   \n1  {'x': 194.87253141831238, 'y': 178.32675044883...   \n2  {'x': 189.23979878597123, 'y': 209.19184886465...   \n\n                       location  \n0   Other Posterior Circulation  \n1  Right Middle Cerebral Artery  \n2  Right Middle Cerebral Artery  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SeriesInstanceUID</th>\n      <th>SOPInstanceUID</th>\n      <th>coordinates</th>\n      <th>location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.2.826.0.1.3680043.8.498.10005158603912009425...</td>\n      <td>1.2.826.0.1.3680043.8.498.10775329348174902199...</td>\n      <td>{'x': 258.3621186176837, 'y': 261.359900373599}</td>\n      <td>Other Posterior Circulation</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.2.826.0.1.3680043.8.498.10022796280698534221...</td>\n      <td>1.2.826.0.1.3680043.8.498.53868409774237283281...</td>\n      <td>{'x': 194.87253141831238, 'y': 178.32675044883...</td>\n      <td>Right Middle Cerebral Artery</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.2.826.0.1.3680043.8.498.10023411164590664678...</td>\n      <td>1.2.826.0.1.3680043.8.498.24186535344744886473...</td>\n      <td>{'x': 189.23979878597123, 'y': 209.19184886465...</td>\n      <td>Right Middle Cerebral Artery</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## 1. 標籤讀取","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom ast import literal_eval\n\n# 讀取多標籤分類的主標籤\ntrain_csv = pd.read_csv('/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv')\n# 我們只保留 SeriesInstanceUID + 14 個 target 欄位\ntargets = [\n    'Left Infraclinoid Internal Carotid Artery',\n    'Right Infraclinoid Internal Carotid Artery',\n    'Left Supraclinoid Internal Carotid Artery',\n    'Right Supraclinoid Internal Carotid Artery',\n    'Left Middle Cerebral Artery',\n    'Right Middle Cerebral Artery',\n    'Anterior Communicating Artery',\n    'Left Anterior Cerebral Artery',\n    'Right Anterior Cerebral Artery',\n    'Left Posterior Communicating Artery',\n    'Right Posterior Communicating Artery',\n    'Basilar Tip',\n    'Other Posterior Circulation',\n    'Aneurysm Present'\n]\ndf_labels = train_csv[['SeriesInstanceUID'] + targets].set_index('SeriesInstanceUID')\n\n# 讀取局部定位 (可選，用於定位或 attention map)\nloc_csv = pd.read_csv('/kaggle/input/rsna-intracranial-aneurysm-detection/train_localizers.csv')\n# 把 coordinates (字串) 轉成 tuple\nloc_csv['coordinates'] = loc_csv['coordinates'].apply(literal_eval)\n# group by series，方便查詢同一序列下的所有 lesion\nloc_dict = loc_csv.groupby('SeriesInstanceUID').apply(\n    lambda d: list(zip(d['SOPInstanceUID'], d['coordinates'], d['location']))\n).to_dict()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T06:10:52.884278Z","iopub.execute_input":"2025-07-30T06:10:52.884472Z","iopub.status.idle":"2025-07-30T06:10:53.120050Z","shell.execute_reply.started":"2025-07-30T06:10:52.884456Z","shell.execute_reply":"2025-07-30T06:10:53.119491Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3896420245.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  loc_dict = loc_csv.groupby('SeriesInstanceUID').apply(\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df_labels.loc[loc_csv['SeriesInstanceUID'][0]].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T06:10:53.120535Z","iopub.execute_input":"2025-07-30T06:10:53.120735Z","iopub.status.idle":"2025-07-30T06:10:53.129928Z","shell.execute_reply.started":"2025-07-30T06:10:53.120716Z","shell.execute_reply":"2025-07-30T06:10:53.128475Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1])"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## 2. DICOM 序列前處理","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pydicom\nimport scipy.ndimage\n\ndef load_dicom_series(series_uid: str,\n                      series_root: str,\n                      target_spacing=(1.0, 1.0, 1.0),\n                      window_center=40,\n                      window_width=300,\n                      normalize=True):\n    \"\"\"\n    - series_uid: SeriesInstanceUID\n    - series_root: e.g. '/kaggle/input/.../series'\n    - target_spacing: (z, y, x) in mm\n    - window_center/width: CT 窗位\n    \"\"\"\n    # 1. 找到該序列所有 DICOM 路徑\n    folder = os.path.join(series_root, series_uid)\n    dicom_paths = sorted(glob.glob(os.path.join(folder, '*.dcm')))\n    # 2. 讀取所有 slice，並排序\n    slices = [pydicom.dcmread(p) for p in dicom_paths]\n    # 依照 InstanceNumber 或 ImagePositionPatient[2] 排序\n    slices.sort(key=lambda s: float(s.InstanceNumber))\n    # 3. 堆成 volume\n    pixel_arrays = np.stack([s.pixel_array.astype(np.float32) for s in slices], axis=0)\n    # 4. 窗寬窗位 (CT)\n    wc, ww = window_center, window_width\n    lower = wc - ww/2\n    upper = wc + ww/2\n    pixel_arrays = np.clip(pixel_arrays, lower, upper)\n    # 5. 正規化到 [0,1]\n    if normalize:\n        pixel_arrays = (pixel_arrays - lower) / (upper - lower)\n    # 6. 取得目前 spacing\n    zs = float(slices[0].SliceThickness)\n    ys, xs = [float(x) for x in slices[0].PixelSpacing]\n    current_spacing = (zs, ys, xs)\n    # 7. 重採樣到 target_spacing\n    resize_factor = np.array(current_spacing) / np.array(target_spacing)\n    new_shape = np.round(pixel_arrays.shape * resize_factor).astype(int)\n    real_resize = new_shape / pixel_arrays.shape\n    volume = scipy.ndimage.zoom(pixel_arrays, real_resize, order=1)\n    return volume  # shape = (new_slices, new_h, new_w)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T06:10:53.130476Z","iopub.execute_input":"2025-07-30T06:10:53.130681Z","iopub.status.idle":"2025-07-30T06:10:53.904044Z","shell.execute_reply.started":"2025-07-30T06:10:53.130663Z","shell.execute_reply":"2025-07-30T06:10:53.903005Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd\nimport pydicom\nimport scipy.ndimage\nfrom ast import literal_eval\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\n# ----------------------------------------\n# 1. 讀取標籤\n# ----------------------------------------\ntrain_csv = pd.read_csv(\n    '/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv'\n)\ntargets = [\n    'Left Infraclinoid Internal Carotid Artery',\n    'Right Infraclinoid Internal Carotid Artery',\n    'Left Supraclinoid Internal Carotid Artery',\n    'Right Supraclinoid Internal Carotid Artery',\n    'Left Middle Cerebral Artery',\n    'Right Middle Cerebral Artery',\n    'Anterior Communicating Artery',\n    'Left Anterior Cerebral Artery',\n    'Right Anterior Cerebral Artery',\n    'Left Posterior Communicating Artery',\n    'Right Posterior Communicating Artery',\n    'Basilar Tip',\n    'Other Posterior Circulation',\n    'Aneurysm Present'\n]\ndf_labels = train_csv.set_index('SeriesInstanceUID')[targets]\n\n# （可選）讀 train_localizers 做 attention 之用\nloc_csv = pd.read_csv(\n    '/kaggle/input/rsna-intracranial-aneurysm-detection/train_localizers.csv'\n)\nloc_csv['coordinates'] = loc_csv['coordinates'].apply(literal_eval)\nloc_dict = loc_csv.groupby('SeriesInstanceUID').apply(\n    lambda d: list(zip(d['SOPInstanceUID'], d['coordinates'], d['location']))\n).to_dict()\n\n\n# ----------------------------------------\n# 2. DICOM 序列前處理函式\n# ----------------------------------------\ndef load_dicom_series(\n    series_uid: str,\n    series_root: str = '/kaggle/input/rsna-intracranial-aneurysm-detection/series',\n    target_spacing: tuple = (1.0, 1.0, 1.0),\n    window_center: float = 40.0,\n    window_width: float = 300.0,\n    normalize: bool = True,\n):\n    \"\"\"\n    1) 讀取並按 InstanceNumber 排序所有 slice\n    2) 窗寬窗位 (windowing)：CT 用 window_center, window_width\n       └ window_center: 亮度中心 (HU)\n       └ window_width: 範圍 (HU)\n    3) clip & normalize 到 [0,1]\n    4) 重採樣到 target_spacing (z,y,x) mm\n    \"\"\"\n    folder = os.path.join(series_root, series_uid)\n    paths = sorted(glob.glob(os.path.join(folder, '*.dcm')))\n    slices = [pydicom.dcmread(p) for p in paths]\n    slices.sort(key=lambda s: float(s.InstanceNumber))\n\n    volume = np.stack([s.pixel_array.astype(np.float32) for s in slices], axis=0)\n\n    # ———— 窗寬窗位說明 ————\n    # window_center, window_width 用來限制 HU 範圍：\n    #   low = center - width/2, high = center + width/2\n    # 這樣 vessels 會更清晰。不同 modality(CTA/MRA/T1/T2) 可以各自調。\n    low = window_center - window_width / 2\n    high = window_center + window_width / 2\n    volume = np.clip(volume, low, high)\n\n    if normalize:\n        volume = (volume - low) / (high - low)\n\n    # ———— Resample 說明 ————\n    # 因為不同序列的 slice thickness / pixel spacing 可能不一，\n    # 我們統一 resample 到 (z,y,x) = target_spacing(mm)\n    zs, ys, xs = float(slices[0].SliceThickness), *map(float, slices[0].PixelSpacing)\n    current_spacing = (zs, ys, xs)\n    resize_factor = np.array(current_spacing) / np.array(target_spacing)\n    new_shape = np.round(volume.shape * resize_factor).astype(int)\n    real_factor = new_shape / volume.shape\n    volume = scipy.ndimage.zoom(volume, real_factor, order=1)\n\n    return volume  # shape = (D, H, W), dtype=float32\n\n\n# ----------------------------------------\n# 3. 自訂 Dataset\n# ----------------------------------------\nclass AneurysmDataset(Dataset):\n    def __init__(\n        self,\n        label_df: pd.DataFrame,\n        series_root: str,\n        uids: list,\n        target_spacing: tuple,\n        window_center: float,\n        window_width: float,\n        modality: str = None,\n        transform=None\n    ):\n        self.label_df = label_df\n        self.series_root = series_root\n        self.uids = uids\n        self.target_spacing = target_spacing\n        self.window_center = window_center\n        self.window_width = window_width\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.uids)\n\n    def __getitem__(self, idx):\n        uid = self.uids[idx]\n        volume = load_dicom_series(\n            series_uid=uid,\n            series_root=self.series_root,\n            target_spacing=self.target_spacing,\n            window_center=self.window_center,\n            window_width=self.window_width,\n        )\n\n        # ———— 這裡示範取中間 3 片當作 3-channel input，如果你要 MCx (2D+1D) 或 3D請調整 ——  \n        D, H, W = volume.shape\n        mid = D // 2\n        img = volume[mid-1:mid+2]  # shape (3, H, W)\n        img = torch.from_numpy(img).float()\n\n        label = self.label_df.loc[uid].values.astype(np.float32)\n        label = torch.from_numpy(label)\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n\n\n# ----------------------------------------\n# 4. 建立 DataLoader 範例\n# ----------------------------------------\nall_uids = df_labels.index.tolist()\nds = AneurysmDataset(\n    label_df=df_labels,\n    series_root='/kaggle/input/rsna-intracranial-aneurysm-detection/series',\n    uids=all_uids,\n    target_spacing=(1.0, 1.0, 1.0),    # ← 需要你決定\n    window_center=40.0,               # ← 需要你決定\n    window_width=300.0,               # ← 需要你決定\n)\nloader = DataLoader(ds, batch_size=8, shuffle=True, num_workers=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T06:10:53.906248Z","iopub.execute_input":"2025-07-30T06:10:53.906597Z","iopub.status.idle":"2025-07-30T06:11:00.394507Z","shell.execute_reply.started":"2025-07-30T06:10:53.906576Z","shell.execute_reply":"2025-07-30T06:11:00.393767Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3863972519.py:40: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  loc_dict = loc_csv.groupby('SeriesInstanceUID').apply(\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# 如果你還沒裝 pydicom，可以先執行：\n# !pip install pydicom\n\nimport pydicom\n\n# DICOM 檔的完整路徑\ndcm_path = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647/1.2.826.0.1.3680043.8.498.10124807242473374136099471315028464450.dcm'\n\n# 讀檔\nds = pydicom.dcmread(dcm_path)\n\n# 取出像素資料（已經是 numpy array）\nimg = ds.pixel_array\n\n# 印出 shape\nprint(\"Image shape:\", img.shape)\n\n# 可以同時看一下 Rows, Columns\nprint(\"Rows × Columns:\", ds.Rows, \"×\", ds.Columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T06:11:00.396120Z","iopub.execute_input":"2025-07-30T06:11:00.396316Z","iopub.status.idle":"2025-07-30T06:11:00.430525Z","shell.execute_reply.started":"2025-07-30T06:11:00.396300Z","shell.execute_reply":"2025-07-30T06:11:00.430020Z"}},"outputs":[{"name":"stdout","text":"Image shape: (512, 512)\nRows × Columns: 512 × 512\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd\nimport pydicom\nimport scipy.ndimage\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom ast import literal_eval\nimport torchvision.models.video as video_models\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\n# ----------------------------------------\n# 1. 標籤讀取\n# ----------------------------------------\ntrain_csv = pd.read_csv(\n    '/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv'\n)\ntargets = [\n    'Left Infraclinoid Internal Carotid Artery',\n    'Right Infraclinoid Internal Carotid Artery',\n    'Left Supraclinoid Internal Carotid Artery',\n    'Right Supraclinoid Internal Carotid Artery',\n    'Left Middle Cerebral Artery',\n    'Right Middle Cerebral Artery',\n    'Anterior Communicating Artery',\n    'Left Anterior Cerebral Artery',\n    'Right Anterior Cerebral Artery',\n    'Left Posterior Communicating Artery',\n    'Right Posterior Communicating Artery',\n    'Basilar Tip',\n    'Other Posterior Circulation',\n    'Aneurysm Present'\n]\ndf_labels = train_csv.set_index('SeriesInstanceUID')[targets]\n\n# ----------------------------------------\n# 2. DICOM 前處理函式\n# ----------------------------------------\ndef load_dicom_series(\n    series_uid: str,\n    series_root: str = '/kaggle/input/rsna-intracranial-aneurysm-detection/series',\n    target_spacing: tuple = (1.0, 1.0, 1.0),\n    apply_windowing: bool = False,\n    window_center: float = 40.0,\n    window_width: float = 300.0,\n    normalize: bool = True\n) -> np.ndarray:\n    folder = os.path.join(series_root, series_uid)\n    dicom_files = sorted(glob.glob(os.path.join(folder, '*.dcm')))\n    if not dicom_files:\n        raise FileNotFoundError(f\"No DICOM files for series {series_uid}\")\n    slices = [pydicom.dcmread(p, stop_before_pixels=False) for p in dicom_files]\n    slices.sort(key=lambda s: float(getattr(s, 'InstanceNumber', 0)))\n    volume = np.stack([s.pixel_array.astype(np.float32) for s in slices], axis=0)\n\n    if apply_windowing:\n        low = window_center - window_width / 2\n        high = window_center + window_width / 2\n        volume = np.clip(volume, low, high)\n        if normalize:\n            volume = (volume - low) / (high - low)\n\n    zs = float(getattr(slices[0], 'SliceThickness', 1.0))\n    ys, xs = map(float, getattr(slices[0], 'PixelSpacing', [1.0, 1.0]))\n    current_spacing = (zs, ys, xs)\n    factor = np.array(current_spacing) / np.array(target_spacing)\n    new_shape = np.round(volume.shape * factor).astype(int)\n    zoom_factor = new_shape / volume.shape\n    volume = scipy.ndimage.zoom(volume, zoom_factor, order=0)\n    return volume\n\n# ----------------------------------------\n# 3. 自訂 Dataset\n# ----------------------------------------\nclass AneurysmDataset(Dataset):\n    def __init__(\n        self,\n        label_df,\n        series_root,\n        uids,\n        num_slices: int = 32,\n        slice_size: tuple = (256, 256),\n        target_spacing: tuple = (1.0, 1.0, 1.0),\n        apply_windowing: bool = False,\n        window_center: float = 40.0,\n        window_width: float = 300.0,\n        transform=None\n    ):\n        self.labels = label_df\n        self.series_root = series_root\n        self.uids = uids\n        self.num_slices = num_slices\n        self.slice_height, self.slice_width = slice_size\n        self.target_spacing = target_spacing\n        self.apply_windowing = apply_windowing\n        self.window_center = window_center\n        self.window_width = window_width\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.uids)\n\n    def __getitem__(self, idx):\n        uid = self.uids[idx]\n        try:\n            volume = load_dicom_series(\n                series_uid=uid,\n                series_root=self.series_root,\n                target_spacing=self.target_spacing,\n                apply_windowing=self.apply_windowing,\n                window_center=self.window_center,\n                window_width=self.window_width\n            )\n        except:\n            volume = np.zeros((self.num_slices, self.slice_height, self.slice_width), dtype=np.float32)\n\n        D, H, W = volume.shape\n        T = self.num_slices\n        if D >= T:\n            idxs = np.linspace(0, D - 1, T).astype(int)\n            vol = volume[idxs]\n        else:\n            vol = np.zeros((T, H, W), dtype=np.float32)\n            vol[:D] = volume\n\n        if (H, W) != (self.slice_height, self.slice_width):\n            zoom = (1, self.slice_height / H, self.slice_width / W)\n            vol = scipy.ndimage.zoom(vol, zoom, order=0)\n\n        img = torch.from_numpy(vol).unsqueeze(0)\n        label = torch.tensor(self.labels.loc[uid].values, dtype=torch.float32)\n        if self.transform:\n            img = self.transform(img)\n        return img, label\n\n# ----------------------------------------\n# 4. 訓練函式與迴圈\n# ----------------------------------------\ndef train_one_epoch(loader, model, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    for imgs, labels in tqdm(loader, desc='Train'): \n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * imgs.size(0)\n    return running_loss / len(loader.dataset)\n\n\ndef validate_one_epoch(loader, model, criterion, device):\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for imgs, labels in tqdm(loader, desc='Val'):\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * imgs.size(0)\n    return val_loss / len(loader.dataset)\n\n\ndef main_train():\n    # 分割 train/val\n    all_uids = df_labels.index.tolist()\n    train_uids, val_uids = train_test_split(all_uids, test_size=0.2, random_state=42)\n\n    train_ds = AneurysmDataset(df_labels, '/kaggle/input/rsna-intracranial-aneurysm-detection/series',\n                                train_uids, num_slices=32, slice_size=(256,256))\n    val_ds = AneurysmDataset(df_labels, '/kaggle/input/rsna-intracranial-aneurysm-detection/series',\n                              val_uids, num_slices=32, slice_size=(256,256))\n    train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0, pin_memory=False)\n    val_loader = DataLoader(val_ds, batch_size=2, shuffle=False, num_workers=0, pin_memory=False)\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = video_models.mc3_18(pretrained=True)\n    model.stem[0] = nn.Conv3d(1,64,(3,7,7),(1,2,2),(1,3,3),bias=False)\n    model.fc = nn.Linear(model.fc.in_features, len(targets))\n    model = model.to(device)\n\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n    epochs = 1\n\n    best_val = float('inf')\n    for epoch in range(1, epochs+1):\n        train_loss = train_one_epoch(train_loader, model, criterion, optimizer, device)\n        val_loss = validate_one_epoch(val_loader, model, criterion, device)\n        scheduler.step()\n        print(f\"Epoch {epoch}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n        # 儲存最佳模型\n        if val_loss < best_val:\n            best_val = val_loss\n            torch.save(model.state_dict(), 'best_aneurysm.pth')\n            print(\"Saved Best Model\")\n\nif __name__ == '__main__':\n    main_train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T06:11:00.431196Z","iopub.execute_input":"2025-07-30T06:11:00.431402Z","execution_failed":"2025-07-30T11:40:10.482Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MC3_18_Weights.KINETICS400_V1`. You can also use `weights=MC3_18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/mc3_18-a90a0ba3.pth\" to /root/.cache/torch/hub/checkpoints/mc3_18-a90a0ba3.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 151MB/s] \nTrain:  33%|███▎      | 582/1762 [2:04:48<3:21:24, 10.24s/it]/usr/local/lib/python3.11/dist-packages/pydicom/pixels/utils.py:222: UserWarning: A value of 'None' for (0028,0008) 'Number of Frames' is invalid, assuming 1 frame\n  warn_and_log(\nTrain:  72%|███████▏  | 1268/1762 [4:27:05<1:35:31, 11.60s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"- IMG shape: (2, 1, 64, 512, 512)\n- Lab shape: (2, 14)\n- \"Out shape: (2, 14)","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport scipy.ndimage\nimport pydicom\nfrom torchvision import models\n\n# ----------------------------------------\n# 1. 定義與訓練時相同的 Dataset\n# ----------------------------------------\nclass AneurysmDataset(Dataset):\n    def __init__(self, series_root, uids, num_slices=32, slice_size=(256,256), target_spacing=(1.0,1.0,1.0)):\n        self.series_root = series_root\n        self.uids = uids\n        self.num_slices = num_slices\n        self.slice_height, self.slice_width = slice_size\n        self.target_spacing = target_spacing\n\n    def __len__(self):\n        return len(self.uids)\n\n    def load_series(self, series_uid):\n        folder = os.path.join(self.series_root, series_uid)\n        paths = sorted(glob.glob(os.path.join(folder, '*.dcm')))\n        slices = [pydicom.dcmread(p, stop_before_pixels=False) for p in paths]\n        slices.sort(key=lambda s: float(getattr(s, 'InstanceNumber', 0)))\n        volume = np.stack([s.pixel_array.astype(np.float32) for s in slices], axis=0)\n        # Resample to target_spacing\n        zs = float(getattr(slices[0], 'SliceThickness',1.0))\n        ys, xs = map(float, getattr(slices[0], 'PixelSpacing',[1.0,1.0]))\n        factor = np.array((zs,ys,xs)) / np.array(self.target_spacing)\n        new_shape = np.round(volume.shape * factor).astype(int)\n        zoom = new_shape / volume.shape\n        volume = scipy.ndimage.zoom(volume, zoom, order=0)\n        return volume\n\n    def __getitem__(self, idx):\n        uid = self.uids[idx]\n        volume = self.load_series(uid)\n        D, H, W = volume.shape\n        T = self.num_slices\n        # sample or pad\n        if D >= T:\n            indices = np.linspace(0, D-1, T).astype(int)\n            vol = volume[indices]\n        else:\n            vol = np.zeros((T,H,W), dtype=np.float32)\n            vol[:D] = volume\n        # resize slices\n        if (H,W) != (self.slice_height, self.slice_width):\n            zoom2 = (1, self.slice_height/H, self.slice_width/W)\n            vol = scipy.ndimage.zoom(vol, zoom2, order=0)\n        img = torch.from_numpy(vol).unsqueeze(0)\n        return uid, img\n\n# ----------------------------------------\n# 2. 載入模型並推論\n# ----------------------------------------\ndef inference_and_submit(model_path: str,\n                         test_series_root: str,\n                         output_csv: str = 'submission.csv',\n                         batch_size: int = 1):\n    # Targets 順序需保持一致\n    targets = [\n        'Left Infraclinoid Internal Carotid Artery',\n        'Right Infraclinoid Internal Carotid Artery',\n        'Left Supraclinoid Internal Carotid Artery',\n        'Right Supraclinoid Internal Carotid Artery',\n        'Left Middle Cerebral Artery',\n        'Right Middle Cerebral Artery',\n        'Anterior Communicating Artery',\n        'Left Anterior Cerebral Artery',\n        'Right Anterior Cerebral Artery',\n        'Left Posterior Communicating Artery',\n        'Right Posterior Communicating Artery',\n        'Basilar Tip',\n        'Other Posterior Circulation',\n        'Aneurysm Present'\n    ]\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    # 建立 MC3_18 架構\n    model = models.video.mc3_18(pretrained=False)\n    model.stem[0] = nn.Conv3d(1,64,(3,7,7),(1,2,2),(1,3,3),bias=False)\n    model.fc = nn.Linear(model.fc.in_features, len(targets))\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model = model.to(device).eval()\n\n    # 測試集\n    test_uids = sorted(os.listdir(test_series_root))\n    test_ds = AneurysmDataset(test_series_root, test_uids)\n    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n\n    results = []\n    with torch.no_grad():\n        for uids, imgs in test_loader:\n            imgs = imgs.to(device)\n            logits = model(imgs)\n            probs = torch.sigmoid(logits).cpu().numpy()\n            for uid, p in zip(uids, probs):\n                results.append([uid] + p.tolist())\n\n    cols = ['SeriesInstanceUID'] + targets\n    sub_df = pd.DataFrame(results, columns=cols)\n    sub_df.to_csv(output_csv, index=False)\n    print(f\"Saved {output_csv}\")\n\nif __name__ == '__main__':\n    inference_and_submit(\n        model_path='best_aneurysm.pth',\n        test_series_root='/kaggle/input/rsna-intracranial-aneurysm-detection/kaggle_evaluation/series',\n        output_csv='submission.csv',\n        batch_size=1\n    )\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-30T11:40:10.482Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}